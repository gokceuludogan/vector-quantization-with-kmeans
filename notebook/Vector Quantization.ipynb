{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir, getcwd\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_train_data(datapath, output_file):\n",
    "    '''Gets train instances and save '''\n",
    "    commands_dirs_by_readers = [join(datapath,f) for f in listdir(datapath) if not isfile(join(datapath, f))]\n",
    "    instances = np.concatenate([np.concatenate([get_mfc_file(join(join(directory, 'komutlar'), f))]) for directory in commands_dirs_by_readers for f in listdir(join(directory, 'komutlar')) if f.endswith('.mfc')])\n",
    "    np.save(output_file, instances)\n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datapoints(filepath):\n",
    "    return np.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfc_file(path):\n",
    "    '''Loads mfc file as matrix'''\n",
    "    return np.loadtxt(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_test_data(datapath, output_file):\n",
    "    '''Gets and saves test instances'''\n",
    "    test_instances = np.concatenate([np.concatenate([get_mfc_file(join(datapath,f))]) for f in listdir(datapath) if f.endswith('.mfc')])\n",
    "    np.save(output_file, test_instances)\n",
    "    return test_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_and_save_train_data('../assignment-1/ProjectData/TrainData', 'train-datapoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_schedule = [1, 2, 3, 4, 6, 8, 10, 12, 16, 20, 24, 28, 32, 40, 48, 56, 64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster(point, centroids):\n",
    "    dist_to_centroids = []   \n",
    "    for centroid in centroids:\n",
    "        dist = distance(point, centroid)\n",
    "        dist_to_centroids.append(dist)\n",
    "    return [i for i in sorted(enumerate(dist_to_centroids), key=lambda x:x[1])][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point1, point2):\n",
    "    return np.linalg.norm(point1-point2, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_distortion(cluster, centroid):\n",
    "    return sum([distance(point, centroid) for point in cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_distortion(clusters):\n",
    "    return sum([cluster_distortion(points, centroid) for centroid, points in clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(points, number_of_clusters):\n",
    "    centroid_indices = random.sample(range(len(points)), number_of_clusters)\n",
    "    centroids = [points[index] for index in centroid_indices]\n",
    "    clusters = [[] for i in range(number_of_clusters)]\n",
    "    terminate = False\n",
    "    last_distortion = total_distortion([(np.matrix(points).mean(0), points)])  \n",
    "    #print('initial')\n",
    "    #print(centroids)         \n",
    "    while terminate == False:\n",
    "        clusters = [[] for i in range(number_of_clusters)]\n",
    "        for point in points:\n",
    "            dist_to_centroids = [distance(point, centroid) for centroid in centroids]\n",
    "            cluster_index = [i[0] for i in sorted(enumerate(dist_to_centroids), key=lambda x:x[1])][0]    \n",
    "            clusters[cluster_index].append(point)\n",
    "        centroids = [np.matrix(points).mean(0) for points in clusters]     \n",
    "        #print('next')\n",
    "        #print(centroids)        \n",
    "        distortion = total_distortion(zip(centroids, clusters))\n",
    "        if last_distortion - distortion < 1.0:\n",
    "            terminate = True\n",
    "        else:\n",
    "            print('Last distortion: ' + str(last_distortion) + ' New distortion: '  + str(distortion))\n",
    "            last_distortion = distortion  \n",
    "    return [(centroid, points) for centroid, points in zip(centroids, clusters)]           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "split_type = 'binary-recursive'\n",
    "train_distortions = []\n",
    "test_distortions = []\n",
    "for number_of_cluster in cluster_schedule:\n",
    "    print('Schedule ' + str(number_of_cluster))\n",
    "    if number_of_cluster == 1:\n",
    "        clusters = [(train_data.mean(0), train_data)]\n",
    "    else:\n",
    "        if split_type == 'binary-recursive':\n",
    "            cluster_to_split = number_of_cluster - len(clusters)\n",
    "            for iteration in range(cluster_to_split):\n",
    "                distortions = []\n",
    "                for centroid, cluster_points in clusters:\n",
    "                    distortions.append(cluster_distortion(cluster_points, centroid))\n",
    "                cluster_index = [i[0] for i in sorted(enumerate(distortions), key=lambda x:x[1], reverse=True)][0]    \n",
    "                centroid, datapoints = clusters[cluster_index]\n",
    "                clusters = clusters + kmeans_clustering(datapoints, 2)\n",
    "                del clusters[cluster_index]\n",
    "        elif split_type == 'binary':\n",
    "            # choose number_of_cluster - len(clusters) and split each of them into two clusters \n",
    "            cluster_to_split = number_of_cluster - len(clusters)\n",
    "            distortions = []\n",
    "            for centroid, cluster_points in clusters:\n",
    "                distortions.append(cluster_distortion(cluster_points, centroid))\n",
    "            cluster_indices_to_split = [i[0] for i in sorted(enumerate(distortions), key=lambda x:x[1], reverse=True)][:cluster_to_split]    \n",
    "            for cluster_index in cluster_indices_to_split:\n",
    "                centroid, datapoints = clusters[cluster_index]\n",
    "                clusters = clusters + kmeans_clustering(datapoints, 2)\n",
    "            for cluster_index in cluster_indices_to_split:\n",
    "                del clusters[cluster_index]\n",
    "                \n",
    "        elif split_type == 'multiple': \n",
    "            # choose one cluster and split into number_of_cluster - len(clusters) clusters\n",
    "            cluster_to_split = number_of_cluster - len(clusters)\n",
    "            distortions = []\n",
    "            for centroid, cluster_points in clusters:\n",
    "                distortions.append(cluster_distortion(cluster_points, centroid))\n",
    "            cluster_index = [i[0] for i in sorted(enumerate(distortions), key=lambda x:x[1], reverse=True)][0]    \n",
    "            centroid, datapoints = clusters[cluster_index]\n",
    "            clusters = clusters + kmeans_clustering(datapoints, cluster_to_split)\n",
    "            del clusters[cluster_index]\n",
    "        else:\n",
    "            print('Not a valid split type')    \n",
    "    train_distortion = total_distortion(clusters)          \n",
    "    train_distortions.append(train_distortion)\n",
    "    test_distortion = 0\n",
    "    for point in test_data:\n",
    "        cluster_index, dist = find_cluster(point, [centroid for centroid, points in clusters])\n",
    "        test_distortion += dist\n",
    "    test_distortions.append(test_distortion)\n",
    "    \n",
    "    print('Train distortion ' + str(train_distortion))\n",
    "    print('Test distortion ' + str(test_distortion))    \n",
    "print(train_distortions)    \n",
    "print(test_distortions)  \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
